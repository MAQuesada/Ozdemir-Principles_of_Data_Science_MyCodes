{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Tensorflow es un módulo open-source de machine learning desarollado por Goolge que se utiliza principalmente por sus capacidades simplificadas de **deep learning and neural network**.La sintaxis de tensorflow (al igual que la de PyBrain) es un poco diferente a nuestra sintaxis normal de scikit-learns```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Tensorflow aprende de una manera diferente ya que siempre está tratando de minimizar una función de error. Lo hace recorriendo iterativamente todo nuestro conjunto de datos y cada cierto tiempo , actualiza nuestro modelo para que se ajuste mejor a los datos.```\n",
    "\n",
    "Es importante señalar que tensorflow no sólo implementa redes neuronales, sino que sino que también puede implementar los modelos más simples. Por ejemplo, vamos a implementar una clásica**LogisticRegression** usando tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Our data set of iris flowers\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df = pd.concat([iris_df, pd.DataFrame(data=iris.target, columns=['target'])], axis=1)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. definir las columans de caracteristicas'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Split them for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df[iris.feature_names], iris_df['target'])\n",
    "\n",
    "categ_columns = []\n",
    "numeric_columns = iris.feature_names\n",
    "\n",
    "# Funciona co ntodos los Estimadores de Tensorflow y su proposito es definir las\n",
    "# caracteristicas definidad para el modelo\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in categ_columns:\n",
    "    vocabulary = X_train[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        feature_name, vocabulary))\n",
    "\n",
    "for feature_name in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Los estimadores(modelos en él) esperan que sus entradas sen un par de objetos:```\n",
    "* Un diccionario en la que las claves son nombres de funciones y los valores son **Tensores(o SparseTensors)** que contienen los datos de funciones correspondientes\n",
    "* Un tensor que contiene una o mas etiquetas\n",
    ">es por eso que necesitamos crear **input_fn()** para devolver un **tf.data.Dataset** que produce pares en ese formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. Crear la función de entrada'''\n",
    "\n",
    "# input_function() especifica como se convierten los datos en tf.data.Dataset que alimentan\n",
    "# la canalizacion de entrada en forma de transmision.\n",
    "\n",
    "# tf.data.Dataset puede admitir multiples funtes como un marco de datos, un .csv y mas\n",
    "\n",
    "\n",
    "from asyncio import base_tasks\n",
    "from codecs import backslashreplace_errors\n",
    "from random import shuffle\n",
    "from turtle import back\n",
    "\n",
    "\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(data_df), label_df)\n",
    "        if(shuffle):\n",
    "            ds = ds.shuffle(1000)\n",
    "        # Combinar consecutivamente los elementos del dataset en batches(subconjuntos).\n",
    "        ds = ds.batch(batch_size=batch_size).repeat(num_epochs)\n",
    "        print(ds)\n",
    "        return ds\n",
    "    return input_function()\n",
    "\n",
    "\n",
    "X_train_input = make_input_fn(X_train,y_train)\n",
    "X_train_input = make_input_fn(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (4040232018.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [26]\u001b[1;36m\u001b[0m\n\u001b[1;33m    classifier.train()in(x=X_train,\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Establecer una \"learning rate(tasa de aprendizaje)\" que es lo rapido que va a aprender el modelo\n",
    "# (preferimos cerca de 0 pq si el modelo no aprende lentamente podría saltarse la resp correcta )\n",
    "# Ademas le estamos diciendo que optimice usando \"Desenso del Gradiente\" pq el modelo\n",
    "# trabajara para minimizar una funcion de error\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=.1)\n",
    "\n",
    "\n",
    "# Build a linear classifier (logistic regression), implicitamente va a usar la misma funcion de\n",
    "# error que la regresion logistica para optimizar (en este caso mediente descenso del gradiente)\n",
    "# Tenemos que decirle el numero de clases explicitamente\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n",
    "                                           optimizer=optimizer,\n",
    "                                           n_classes=3)\n",
    "                                           \n",
    "# Fit model. Uses error optimization techniques like stochastic gradient descent\n",
    "classifier.train(X_train, y_train,\n",
    "                 steps=1000)# number of iterations(more interation more chance to learn the model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37964de45fa06bc99b754cfc54b483ffac9c133df6b16baa187ef33bd89a6318"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
